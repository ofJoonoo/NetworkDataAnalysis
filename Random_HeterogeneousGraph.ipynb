{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lFcZ4jqgTlYe"
   },
   "source": [
    "# 1. Environment Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JjSisEbzTnSX",
    "outputId": "3082c682-9ccd-4b5a-d660-49b569c50a87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gVGKnOJZToka",
    "outputId": "457edd27-2eb2-419b-fc93-9b0c8f431f28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.2/239.2 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.4/52.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.1/109.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.6/485.6 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m572.7/572.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4o03PewiTsVT",
    "outputId": "fe19ddba-2e80-410b-a31d-d3fc4b1e159b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import time\n",
    "from dgl.nn import GraphConv, SAGEConv, GATConv, HeteroGraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xwxF1gfmXgnn",
    "outputId": "42ebd63c-1d6a-48d5-b981-8917b6406002"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X2ZyKLbmT2qq"
   },
   "source": [
    "# 2. Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "H7RFdLWsUpdy"
   },
   "outputs": [],
   "source": [
    "# Assign node, edge\n",
    "n_users = 1000 #node\n",
    "n_items = 500 #node\n",
    "n_follows = 3000 #edge\n",
    "n_clicks = 5000 #edge\n",
    "n_dislikes = 500 #edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lVAsfKYeVDVP"
   },
   "outputs": [],
   "source": [
    "# Assign Parameter\n",
    "n_hetero_features = 10\n",
    "n_user_classes = 5\n",
    "n_max_clicks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VmPZJ-KaUcpP"
   },
   "outputs": [],
   "source": [
    "# Create random edges\n",
    "follow_src = np.random.randint(0, n_users, n_follows)\n",
    "follow_dst = np.random.randint(0, n_users, n_follows)\n",
    "click_src = np.random.randint(0, n_users, n_clicks)\n",
    "click_dst = np.random.randint(0, n_items, n_clicks)\n",
    "dislike_src = np.random.randint(0, n_users, n_dislikes)\n",
    "dislike_dst = np.random.randint(0, n_items, n_dislikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qkYu95AL79zn",
    "outputId": "049572b7-0097-40d5-dab6-e6250998ca4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([770,  98, 217, ..., 358, 314, 911])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#np.random.randint() 0부터 n_users까지 정수 중 n_follows개의 랜덤 정수\n",
    "follow_src=np.random.randint(0,n_users,n_follows)\n",
    "follow_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EPi7pp3ZXC_0"
   },
   "outputs": [],
   "source": [
    "hetero_graph = dgl.heterograph({\n",
    "    ('user', 'follow', 'user'): (follow_src, follow_dst),\n",
    "    ('user', 'followed-by', 'user'): (follow_dst, follow_src),\n",
    "    ('user', 'click', 'item'): (click_src, click_dst),\n",
    "    ('item', 'clicked-by', 'user'): (click_dst, click_src),\n",
    "    ('user', 'dislike', 'item'): (dislike_src, dislike_dst),\n",
    "    ('item', 'disliked-by', 'user'): (dislike_dst, dislike_src)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GM39u8SfI0e"
   },
   "source": [
    "### 선언한 그래프가 GPU에서 동작하도록 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iEajT4_1Zwzz"
   },
   "outputs": [],
   "source": [
    "hetero_graph = hetero_graph.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b33kMGuw3CJG",
    "outputId": "5ddf5830-26cd-456c-ac6b-23ae52bcd806"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes={'item': 500, 'user': 1000},\n",
       "      num_edges={('item', 'clicked-by', 'user'): 5000, ('item', 'disliked-by', 'user'): 500, ('user', 'click', 'item'): 5000, ('user', 'dislike', 'item'): 500, ('user', 'follow', 'user'): 3000, ('user', 'followed-by', 'user'): 3000},\n",
       "      metagraph=[('item', 'user', 'clicked-by'), ('item', 'user', 'disliked-by'), ('user', 'item', 'click'), ('user', 'item', 'dislike'), ('user', 'user', 'follow'), ('user', 'user', 'followed-by')])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetero_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMCOspiXWRPs"
   },
   "source": [
    "# 3. Assign Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "a2QsV3e0XHic"
   },
   "outputs": [],
   "source": [
    "# Assign Parameter\n",
    "n_hetero_features = 256\n",
    "n_user_classes = 5\n",
    "n_max_clicks = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCNX8mcPSG4O"
   },
   "outputs": [],
   "source": [
    "#torch.randn(): normal distribution을 따르는 난수 생성(size 크기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QTtbWdNzWriI"
   },
   "outputs": [],
   "source": [
    "# Assign Node Features\n",
    "#Cannot assign node feature \"feature\" on device cpu to a graph on device cuda:0. Call DGLGraph.to() to copy the graph to the same device.\n",
    "\n",
    "hetero_graph.nodes['user'].data['feature'] = torch.randn(n_users, n_hetero_features).to(device)\n",
    "hetero_graph.nodes['item'].data['feature'] = torch.randn(n_items, n_hetero_features).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "X_WeS20QWSqy"
   },
   "outputs": [],
   "source": [
    "# Assign Label Data\n",
    "hetero_graph.nodes['user'].data['label'] = torch.randint(0, n_user_classes, (n_users,)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qvcx5EdZWQe_"
   },
   "outputs": [],
   "source": [
    "# Randomly generate training masks on user nodes and click edges\n",
    "\n",
    "# hetero_graph.nodes['user'].data['train_mask'] = torch.zeros(n_users, dtype=torch.bool).bernoulli(0.6).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vC5vct2O3S6k"
   },
   "outputs": [],
   "source": [
    "train_list = torch.zeros(n_users, dtype=torch.bool).bernoulli(0.6).to(device).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kz1iafst4RIU",
    "outputId": "535d35e0-608b-4910-c696-d439e2f6657f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_list = []\n",
    "for i in train_list:\n",
    "  if i==False:\n",
    "    test_list.append(True)\n",
    "  else:\n",
    "    test_list.append(False)\n",
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "w-qa65Zk4ybl"
   },
   "outputs": [],
   "source": [
    "hetero_graph.nodes['user'].data['train_mask'] =  torch.BoolTensor(train_list).to(device)\n",
    "hetero_graph.nodes['user'].data['test_mask'] =  torch.BoolTensor(test_list).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mc0U9F-PX1NS"
   },
   "source": [
    "# 4. Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "cezhqBJESv1g"
   },
   "outputs": [],
   "source": [
    "# Define a Heterograph Conv model\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, in_feats, hid_feats, out_feats, rel_names):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = HeteroGraphConv({\n",
    "            rel: GraphConv(in_feats, hid_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "        \n",
    "        self.conv2 = HeteroGraphConv({\n",
    "            rel: GraphConv(hid_feats, out_feats)\n",
    "            for rel in rel_names}, aggregate='sum')\n",
    "\n",
    "    def forward(self, graph, inputs):\n",
    "        # inputs are features of nodes\n",
    "        h = self.conv1(graph, inputs)\n",
    "        h = {k: F.relu(v) for k, v in h.items()}\n",
    "        h = self.conv2(graph, h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "jrXQxDGATK27"
   },
   "outputs": [],
   "source": [
    "model = RGCN(n_hetero_features, 128, n_user_classes, hetero_graph.etypes).to(device) #model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fnbgCvdGYkEo"
   },
   "outputs": [],
   "source": [
    "# 학습에 필요한 데이터 할당 (목적: 유저 클래스 분류)\n",
    "user_feats = hetero_graph.nodes['user'].data['feature']\n",
    "item_feats = hetero_graph.nodes['item'].data['feature']\n",
    "labels = hetero_graph.nodes['user'].data['label']\n",
    "train_mask = hetero_graph.nodes['user'].data['train_mask']\n",
    "test_mask = hetero_graph.nodes['user'].data['test_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t8eZ7rm2Z6Yu",
    "outputId": "2a6517dd-a050-4fe5-82af-c592f5c6b1a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cuda', index=0),\n",
       " device(type='cuda', index=0),\n",
       " device(type='cuda', index=0))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hetero_graph.device, item_feats.device, user_feats.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1_c6vzhMYlqQ",
    "outputId": "24c3b740-c2ed-4773-c3dd-83a70ae89069"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/dgl/backend/pytorch/tensor.py:352: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  assert input.numel() == input.storage().size(), \"Cannot convert view \" \\\n"
     ]
    }
   ],
   "source": [
    "node_features = {'user': user_feats, 'item': item_feats}\n",
    "h_dict = model(hetero_graph, {'user': user_feats, 'item': item_feats})\n",
    "h_user = h_dict['user']\n",
    "h_item = h_dict['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "tzEoYPC8pCRq"
   },
   "outputs": [],
   "source": [
    "logits = model(hetero_graph, node_features)['user']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aNBKEurUpIZO",
    "outputId": "ad4e177b-6c05-4aba-a09d-3493d0c5e983"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4516,  2.1322,  0.6942,  1.6501, -1.4908],\n",
       "        [ 1.7404,  0.0233, -0.5368, -0.2783, -0.2243],\n",
       "        [ 0.1508, -0.1655, -0.1816,  0.4062, -0.7211],\n",
       "        ...,\n",
       "        [ 0.5730,  0.4671,  0.5902,  0.8492, -0.5441],\n",
       "        [ 0.3838, -0.1043, -2.4252,  1.5405, -0.8883],\n",
       "        [ 0.2225,  1.1439,  0.6740,  0.5679, -1.0437]], device='cuda:0',\n",
       "       grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits[train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4991eF6Ym1l",
    "outputId": "ae1d5c21-daa6-4bf9-9015-caa5b459892e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "Epoch 00000 | Loss 8.6878 | Accuracy 0.2136 \n",
      "0.0\n",
      "Epoch 00010 | Loss 8.6908 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00020 | Loss 8.6939 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00030 | Loss 8.6969 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00040 | Loss 8.6999 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00050 | Loss 8.7029 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00060 | Loss 8.7059 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00070 | Loss 8.7089 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00080 | Loss 8.7119 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00090 | Loss 8.7149 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00100 | Loss 8.7179 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00110 | Loss 8.7208 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00120 | Loss 8.7238 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00130 | Loss 8.7267 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00140 | Loss 8.7297 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00150 | Loss 8.7326 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00160 | Loss 8.7356 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00170 | Loss 8.7385 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00180 | Loss 8.7414 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00190 | Loss 8.7443 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00200 | Loss 8.7472 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00210 | Loss 8.7501 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00220 | Loss 8.7531 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00230 | Loss 8.7560 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00240 | Loss 8.7589 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00250 | Loss 8.7617 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00260 | Loss 8.7646 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00270 | Loss 8.7675 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00280 | Loss 8.7703 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00290 | Loss 8.7732 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00300 | Loss 8.7760 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00310 | Loss 8.7788 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00320 | Loss 8.7817 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00330 | Loss 8.7845 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00340 | Loss 8.7873 | Accuracy 0.2186 \n",
      "0.0\n",
      "Epoch 00350 | Loss 8.7901 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00360 | Loss 8.7930 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00370 | Loss 8.7958 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00380 | Loss 8.7986 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00390 | Loss 8.8014 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00400 | Loss 8.8042 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00410 | Loss 8.8070 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00420 | Loss 8.8098 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00430 | Loss 8.8126 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00440 | Loss 8.8153 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00450 | Loss 8.8181 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00460 | Loss 8.8209 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00470 | Loss 8.8236 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00480 | Loss 8.8264 | Accuracy 0.2161 \n",
      "0.0\n",
      "Epoch 00490 | Loss 8.8291 | Accuracy 0.2161 \n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(500):\n",
    "    model.train()\n",
    "    # forward propagation by using all nodes and extracting the user embeddings\n",
    "    logits = model(hetero_graph, node_features)['user']\n",
    "    \n",
    "    # compute loss\n",
    "    train_loss = criterion(logits[train_mask], labels[train_mask])\n",
    "    if epoch % 10 == 0:\n",
    "        print(train_loss.item())\n",
    "        \n",
    "    # backward propagation\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # evaluation\n",
    "    num_correct = 0\n",
    "    num_tests = 0\n",
    "    if epoch % 10 == 0:\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "        logits = model(hetero_graph, node_features)['user']\n",
    "        val_loss = criterion(logits[test_mask], labels[test_mask])\n",
    "        acc = (logits[test_mask].argmax(dim=1) == labels[test_mask]).float().mean().item()\n",
    "        print( \"Epoch {:05d} | Loss {:.4f} | Accuracy {:.4f} \".format(\n",
    "        epoch, val_loss.item(), acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
